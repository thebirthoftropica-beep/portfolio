# 新聞社校閲業務特化型LLM (Based on Llama-Elyza-JP-8b)

## 概要
地方新聞社における校閲業務の効率化を目指し、オープンソースの大規模言語モデル（LLM）である `Elyza-JP-8b` をファインチューニングしたモデルの構築ログおよび検証コードです。

本モデルの導入および社内業務フローへの組み込みにより、**校閲業務における工数を約50％削減**する成果を達成しました。

## 背景・課題
記事の校閲業務において、従来のルールベースのチェックツールでは、文脈に依存する誤字や、事実関係の不整合（ハルシネーションの逆検知）までは対応しきれず、最終的に熟練記者による目視確認に多大な時間を要していました。

## アプローチ
* **ベースモデル**: `elyza/ELYZA-japanese-Llama-2-7b` (※実際に使用したモデル名に合わせて修正してください)
* **手法**: QLoRA (Quantized Low-Rank Adapter) を用いたパラメータ効率の良いファインチューニング
* **データセット**: 社内の過去記事データおよび校閲修正履歴をもとに作成した、誤り文と修正文のペアデータセット（※本リポジトリには含まれていません）
* **環境**: Google Colab (T4 GPU / A100 GPU)

## 実装内容
1.  **Preprocessing**: 新聞記事特有の記法に対応するためのデータ前処理
2.  **Fine-tuning**: `PEFT` ライブラリを用いたLoRA学習
3.  **Evaluation**: 学習前後での出力精度の比較検証

## 成果
* 論理的な整合性チェックにおいて、ベースモデル比で精度が向上。
* 校閲補助ツールとして実務導入し、担当者の作業時間を半減させることに成功。

## 使用技術・ライブラリ
* Python
* PyTorch
* Transformers (Hugging Face)
* PEFT / Bitsandbytes / TRL
